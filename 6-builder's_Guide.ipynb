{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3270e750",
   "metadata": {},
   "source": [
    "# Builders’ Guide\n",
    "Details of the APIs: how they work. Key components of deep learning computation, namely model construction, parameter access and initialization, designing custom layers and blocks, reading and writing models to disk, and leveraging GPUs to achieve dramatic speedups.\n",
    "## 6.1. Layers and Modules\n",
    "Linear models with a single output neural network, consist of a single neuron: \n",
    "1. takes some set of inputs\n",
    "2. generates a corresponding scalar output \n",
    "3. has a set of associated parameters that can be updated to optimize some objective function of interest.\n",
    "\n",
    "Networks with multiple outputs / layers:\n",
    "1. take a set of inputs\n",
    "2. generate corresponding outputs\n",
    "3. described by a set of tunable parameters. \n",
    "\n",
    "For MLPs and its layers: \n",
    "1. take raw inputs/features\n",
    "2. generate outputs/predictions\n",
    "3. possesses parameters/combined parameters form all constituent layers\n",
    "\n",
    "Neural network **module** for implement the complex networks. It can be a single layer, a component consisting of multiple layers, or the model.   \n",
    "A module is represented by a **class**, an subclass of it must define a forward propagation method (transforms input into output, store necessary parameters), and process a backpropagation method (calculate gradients, not need to worry).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac63b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efc141",
   "metadata": {},
   "source": [
    "Implement a network with 1 fully connected hidden layer, 256 units and ReLU activation, and a fully connected output layer, 10 units, no activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1a1c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c506f5",
   "metadata": {},
   "source": [
    "Construct model by instantiating an ```nn.Sequential```, defines a special kind of ```Module```. Each 2 fully connected layers is an instance of the ```Linear``` class which is a subclass of ```Module```.  \n",
    "The ```forward``` propagation method chains each module in the list and pass the output of each as input to the next.  \n",
    "Invoke models via ```net(X)```  (a shorthand for ```net.__call__(X)```) to obtain output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0eb63f",
   "metadata": {},
   "source": [
    "### 6.1.1. A Custom Module\n",
    "Basic functionality that each module must provide:\n",
    "1. Ingest input data as arguments to its forward propagation method.\n",
    "2. Generate an output by having the forward propagation method return a value. Note that the output may have a different shape from the input. \n",
    "3. Calculate the gradient of its output with respect to its input, which can be accessed via its backpropagation method.\n",
    "4. Store and provide access to those parameters necessary for executing the forward propagation computation.\n",
    "5. Initialize model parameters as needed.\n",
    "\n",
    "Code a module for an MLP with 1 hidden layer with 256 hidden units and a 10-dimensional output layer. Supply only ```__init__``` method  and the forward propagation method.  \n",
    "- in ```forward``` method: input X, calculate hidden representation + activation applied, output the logits.\n",
    "- ```__init__```invokes the parent's init via ```super().__init__()```\n",
    "- instantiate 2 fully connected layers, assigning to ```self.hidden```, ```self.out```. System will generate backpropagation automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fb013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the constructor of the parent class nn.Module to perform\n",
    "        # the necessary initialization\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.out = nn.LazyLinear(10)\n",
    "\n",
    "    # Define the forward propagation of the model, that is, how to return the\n",
    "    # required model output based on the input X\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53b4fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccaf6c",
   "metadata": {},
   "source": [
    "### 6.1.2. The Sequential Module\n",
    "```Sequential``` is used to daisy-chain other modules together. For our simplified sequential we need 2 methods:\n",
    "1. A method for appending modules one by one to a list.\n",
    "2. A forward propagation method for passing an input through the chain of modules, in the same order as they were appended.\n",
    "\n",
    "- in ```__init__```: add module by calling ```add_modules``` method.\n",
    "- in ```forward```propagation method, each added module is executedin the order they added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e6fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same functionality of the default Sequential\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for module in self.children():\n",
    "            X = module(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef93e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad29863",
   "metadata": {},
   "source": [
    "### 6.1.3. Executing Code in the Forward Propagation Method\n",
    "Not all architectures are simple daisy chains. We aim to perform arbitrary mathematical operations.  \n",
    "So far all operations act on network's activation and its parameters. We also want to act on terms that neigher the output of previous layer nor updatable parameters, which is called **constant parameters**. We implement a ```FixedHiddenMLP``` class as follows:\n",
    "- weights are initialized randomly, which is not a model parameter and never updated by backpropagation.\n",
    "- run a while-loop to ensure the output's $\\ell_1$ norm is smaller than 1, if not, divide output by 2.\n",
    "- return the sum of the entiries in X.\n",
    "\n",
    "Above may not useful but just for showing how to use arbitrary code into NN flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b1c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Random weight parameters that will not compute gradients and\n",
    "        # therefore keep constant during training\n",
    "        self.rand_weight = torch.rand((20, 20))\n",
    "        self.linear = nn.LazyLinear(20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(X @ self.rand_weight + 1)\n",
    "        # Reuse the fully connected layer. This is equivalent to sharing\n",
    "        # parameters with two fully connected layers\n",
    "        X = self.linear(X)\n",
    "        # Control flow\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478bb849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0721, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35aaad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3910, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mix modules together example\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.LazyLinear(64), nn.ReLU(),\n",
    "                                 nn.LazyLinear(32), nn.ReLU())\n",
    "        self.linear = nn.LazyLinear(16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.LazyLinear(20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a55df3",
   "metadata": {},
   "source": [
    "### 6.1.4. Summary\n",
    "- Individual layers can be modules. Many layers can comprise a module. Many modules can comprise a module.\n",
    "- a Module can contain code. Modules can do parameter initialization and backpropagation.\n",
    "- Use ```Sequential``` to handle sequential concatenations of layers and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed07c5",
   "metadata": {},
   "source": [
    "## 6.2. Parameter Management\n",
    "- Accessing parameters for debugging, diagnostics, and visualizations.\n",
    "- Sharing parameters across different model components.\n",
    "\n",
    "### 6.2.1. Parameter Access\n",
    "When a model is defined via ```Sequential``` class: access layer by indexing. Each layer's parameters are in the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4b1450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.LazyLinear(8),\n",
    "                    nn.ReLU(),\n",
    "                    nn.LazyLinear(1))\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1557f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.1904, -0.0517, -0.1419, -0.3515, -0.2102, -0.0083,  0.2476,  0.0567]])),\n",
       "             ('bias', tensor([0.3388]))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b613bc",
   "metadata": {},
   "source": [
    "#### 6.2.1.1. Targeted Parameters\n",
    "Each parameter is represented as an instance of the parameter class. To access the underlying numerical values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd39d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.nn.parameter.Parameter, tensor([0.3388]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract bias from 2nd NN layer, return a parameter class instance\n",
    "type(net[2].bias), net[2].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bfec0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter object contains value, gradient, and additional info\n",
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b535ab",
   "metadata": {},
   "source": [
    "#### 6.2.1.2. All Parameters at Once\n",
    "Access parameters of all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b6247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight', torch.Size([8, 4])),\n",
       " ('0.bias', torch.Size([8])),\n",
       " ('2.weight', torch.Size([1, 8])),\n",
       " ('2.bias', torch.Size([1]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6dba8",
   "metadata": {},
   "source": [
    "### 6.2.2. Tied Parameters\n",
    "Share parameters across multiple layers. Parameters between layer are tied and represented by the same tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5638a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# We need to give the shared layer a name so that we can refer to its parameters\n",
    "shared = nn.LazyLinear(8)\n",
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.LazyLinear(1))\n",
    "\n",
    "net(X)\n",
    "# Check whether the parameters are the same\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# Make sure that they are actually the same object rather than just having the same value\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af9b00",
   "metadata": {},
   "source": [
    "### 6.2.3 Summary\n",
    "Ways to access model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92892bd1",
   "metadata": {},
   "source": [
    "## 6.3. Parameter Initialization\n",
    "How to initialize parameters properly:  \n",
    "Default is weight/bias are uniformly drawn from a range computed from the input & output dimension. ```nn.init``` module provides preset initialization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b6aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0552c975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(), nn.LazyLinear(1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f74be",
   "metadata": {},
   "source": [
    "### 6.3.1. Built-in Initialization\n",
    "Initialize all weight parameters as Gaussian random variables with standard deviation = 0.01, bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea083eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0032, -0.0064, -0.0138, -0.0060]), tensor(0.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.normal_(module.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(module.bias)\n",
    "\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2036da99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize all parameter to a given constant\n",
    "def init_constant(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.constant_(module.weight, 1)\n",
    "        nn.init.zeros_(module.bias)\n",
    "\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce0ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0935, -0.3470, -0.3493,  0.4180])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "# apply different initializers for certain blocks. \n",
    "def init_xavier(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "def init_42(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.constant_(module.weight, 42)\n",
    "\n",
    "# initialize 1st layer with Xavier initializer\n",
    "net[0].apply(init_xavier)\n",
    "# initialize 2nd layer to constant 42\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135278dc",
   "metadata": {},
   "source": [
    "#### 6.3.1.1. Custom Initialization\n",
    "For initialization methods that are not provided by the framwork, define a function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f2c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1898, -0.0000, -0.0000,  0.0000],\n",
       "        [ 6.6734, -5.5504, -0.0000, -7.9045]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# U(5,10) with p=1/4, 0 with p=1/2, U(-10,-5) with p=1/4\n",
    "def my_init(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in module.named_parameters()][0])\n",
    "        nn.init.uniform_(module.weight, -10, 10)\n",
    "        module.weight.data *= module.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f62f5f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set parameters directly\n",
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c75f7d",
   "metadata": {},
   "source": [
    "### 6.3.2 Summary\n",
    "We can initialize parameters using built-in and custom initializers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e9c1e",
   "metadata": {},
   "source": [
    "## 6.4. Lazy Initialization\n",
    "For the unintuitive things: define the network architectures without specifying the input dimensionality, add layers without specifying the output dimension of the previous layer, initialize parameters before providing enough info to determine how many parameters we need.  \n",
    "The framework **defers initialization**, waiting until the first time we pass data through the model, to infer the sizes of each layer on the fly. Next, we go deeper into the mechanics of initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0001fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee04169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UninitializedParameter>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate an MLP\n",
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "\n",
    "# the framework has not initialized any parameters.\n",
    "net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae06cc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass data through then the framwork initialize parameters.\n",
    "X = torch.rand(2, 20)\n",
    "net(X)\n",
    "\n",
    "net[0].weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421fd9d",
   "metadata": {},
   "source": [
    "With input dimensionality, the framework can find the shape of the first layer. With the shape of first layer, the framework compute the computational graph so all shapes are known. Only the first layer requires lazy initialization, the framework initializes sequentially. Once all shapes are known, the framework initialize the parameters.   \n",
    "The following method passes in dummy inputs through the network for a dry run to infer all parameter shapes and subsequently initializes the parameters. It will be used later when default random initializations are not desired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71079648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry run for better initialization.\n",
    "@d2l.add_to_class(d2l.Module)  #@save\n",
    "def apply_init(self, inputs, init=None):\n",
    "    self.forward(*inputs)\n",
    "    if init is not None:\n",
    "        self.net.apply(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6691612",
   "metadata": {},
   "source": [
    "### 6.4.1 Summary\n",
    "Lazy initialization can be convenient, allowing the framework to infer parameter shapes automatically, making it easy to modify architectures and eliminating one common source of errors. We can pass data through the model to make the framework finally initialize parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898d901",
   "metadata": {},
   "source": [
    "## 6.5. Custom Layers\n",
    "### 6.5.1. Layers without Parameters\n",
    "Construct a custom layer that does not have any parameters of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5ee0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82e97914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da8aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of usage\n",
    "layer = CenteredLayer()\n",
    "layer(torch.tensor([1.0, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5bbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use as a component in complex models\n",
    "net = nn.Sequential(nn.LazyLinear(128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39bc247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5879e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of model usage, mean should be 0\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b55bb6",
   "metadata": {},
   "source": [
    "### 6.5.2. Layers with Parameters\n",
    "Implement a fully connected layer with \n",
    "- 2 parameters: weight and bias \n",
    "- 2 input arguments: in_units and units, denoted # inputs and # outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5caa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4fd224f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.0234, -0.0247,  2.1286],\n",
       "        [ 0.1858, -0.2367, -1.3932],\n",
       "        [ 1.7267,  1.1290, -0.4259],\n",
       "        [-0.0433,  0.5845, -0.0928],\n",
       "        [-0.4610,  0.1135,  0.5796]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the MyLinear class\n",
    "linear = MyLinear(5, 3)\n",
    "# access model parameters\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9367bab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7767, 0.0470, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward propagation calculations using custom layers\n",
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8566a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6446],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models using custom layers\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eab5a0",
   "metadata": {},
   "source": [
    "### 6.5.3 Summary\n",
    "Design custom layers via the layer class, which allows us to define flexible new layers. Layers can have local parameters, which can be created through build-in functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5442205",
   "metadata": {},
   "source": [
    "## 6.6. File I/O\n",
    "Save the learned models or when running a long training process, periodically save intermediate results.\n",
    "### 6.6.1. Loading and Saving Tensors¶\n",
    "Invoke ```load``` and ```save``` functions to read and write individual tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1f1d361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a020a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coco\\AppData\\Local\\Temp\\ipykernel_21700\\2392936229.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x2 = torch.load('x-file')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data from the file\n",
    "x2 = torch.load('x-file')\n",
    "x2 == x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6da1ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coco\\AppData\\Local\\Temp\\ipykernel_21700\\1934923035.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x2, y2 = torch.load('x-files')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store a list of tensors and read back\n",
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec37b9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coco\\AppData\\Local\\Temp\\ipykernel_21700\\1129133509.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mydict2 = torch.load('mydict')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write and read a dictionary that maps from strings to tensors\n",
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f0f1e",
   "metadata": {},
   "source": [
    "### 6.6.2. Loading and Saving Model Parameters\n",
    "Load and save entire networks using build-in functionalities. Save the **parameters** and not the entire model. The architecture need to be specified separately.  \n",
    "To reinstate a model, we need to generate the architecture in code then load the parameters from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff59809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af7b38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the parameters as a file\n",
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fee2c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coco\\AppData\\Local\\Temp\\ipykernel_21700\\150697765.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clone.load_state_dict(torch.load('mlp.params'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recover the model\n",
    "# instantiate the original MLP model\n",
    "clone = MLP()\n",
    "# read parameters from the file\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12c12f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify if is the same\n",
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aaa96b",
   "metadata": {},
   "source": [
    "### 6.6.3 Summary\n",
    "- ```save``` and ```load``` functions can be used for file I/O for tensors.\n",
    "- save and load the parameters of a network via a parameter dictionary\n",
    "- save the architecture has to be done in code rather than in parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96827c11",
   "metadata": {},
   "source": [
    "## 6.7 GPUs\n",
    "How to use a single NVIDIA GPU for calculations.  \n",
    "In PyTorch, every array has a device; we often refer it as a **context**. By default, all variables and associated computation have been assigned to the CPU. Other contexts might be various GPUs.  \n",
    "By assigning arrays to contexts intelligently, we can minimize the time spent transferring data between devices. For example, when training neural networks on a server with a GPU, we typically prefer for the model’s parameters to live on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d388c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use google colab\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed886931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools, pip\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pip-25.3 setuptools-80.9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "2d22e751b3f54796a41c4d67b4ff24b5",
       "pip_warning": {
        "packages": [
         "_distutils_hack"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting d2l\n",
      "  Using cached d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
      "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: d2l\n",
      "Successfully installed d2l-1.0.3\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.5.7)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.17.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.7.1)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Downloading jupyterlab-4.5.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.8.15)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.4.9)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.7.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (80.9.0)\n",
      "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (5.9.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->jupyter) (4.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.6.10)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.0.16)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (3.1.6)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (25.1.0)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (5.10.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (2.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (0.23.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (1.3.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.2.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter) (4.26.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.30.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (2.14.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (4.12.1)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (7.7.0)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (3.11)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter) (25.1.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (25.10.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.8.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.4.0)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Downloading async_lru-2.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter)\n",
      "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.17.0)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter)\n",
      "  Downloading json5-0.13.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.5.0)\n",
      "Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab-4.5.2-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "Downloading async_lru-2.1.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading json5-0.13.0-py3-none-any.whl (36 kB)\n",
      "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: numpy, json5, jedi, async-lru, pandas, matplotlib, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.0.2\n",
      "\u001b[2K    Uninstalling numpy-2.0.2:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.0.2━━━━━━\u001b[0m \u001b[32m 0/10\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [jedi]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [jedi]\n",
      "\u001b[2K    Uninstalling pandas-2.2.2:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [jedi]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.2━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.0━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.0:[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [jupyter]8/10\u001b[0m [jupyterlab]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "d2l 1.0.3 requires jupyter==1.0.0, but you have jupyter 1.1.1 which is incompatible.\n",
      "d2l 1.0.3 requires matplotlib==3.7.2, but you have matplotlib 3.10.8 which is incompatible.\n",
      "d2l 1.0.3 requires matplotlib-inline==0.1.6, but you have matplotlib-inline 0.2.1 which is incompatible.\n",
      "d2l 1.0.3 requires numpy==1.23.5, but you have numpy 2.4.1 which is incompatible.\n",
      "d2l 1.0.3 requires pandas==2.0.3, but you have pandas 2.3.3 which is incompatible.\n",
      "d2l 1.0.3 requires requests==2.31.0, but you have requests 2.32.4 which is incompatible.\n",
      "d2l 1.0.3 requires scipy==1.10.1, but you have scipy 1.16.3 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-lru-2.1.0 jedi-0.19.2 json5-0.13.0 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.5.2 jupyterlab-server-2.28.0 matplotlib-3.10.8 numpy-2.4.1 pandas-2.3.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "828d76f1a4074b74bb5696423724aad5",
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits",
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install -U pip setuptools wheel\n",
    "%pip install --no-deps d2l\n",
    "%pip install -U numpy pandas matplotlib jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa0c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a1fda",
   "metadata": {},
   "source": [
    "### 6.7.1. Computing Devices\n",
    "Specify devices for storage and calculation. By default the tensors are created in the main memory and then CPU is used for calculation. CPU and GPU can be indicated by ```torch.device('cpu)``` and ```torch.device('cuda')```. ```cpu``` means all physical CPUs and memory. ```gpu```represents one card and the corresponding memory. ```torch.device(f'cuda:{i}')``` to represent the $i^{th}$ GPU stats at 0 (```gpu:0``` = ```gpu```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8f067b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cpu():  #@save\n",
    "    \"\"\"Get the CPU device.\"\"\"\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def gpu(i=0):  #@save\n",
    "    \"\"\"Get a GPU device.\"\"\"\n",
    "    return torch.device(f'cuda:{i}')\n",
    "\n",
    "cpu(), gpu(), gpu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f59a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the number of available GPUs\n",
    "def num_gpus():  #@save\n",
    "    \"\"\"Get the number of available GPUs.\"\"\"\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "num_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1b4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'), [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run code if requested GPUs not exist\n",
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if num_gpus() >= i + 1:\n",
    "        return gpu(i)\n",
    "    return cpu()\n",
    "\n",
    "def try_all_gpus():  #@save\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
    "    return [gpu(i) for i in range(num_gpus())]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85926da",
   "metadata": {},
   "source": [
    "### 6.7.2. Tensors and GPUs\n",
    "By default, tensors are created on the CPU. We can query the device where the tensor is located.  \n",
    "Whenever we want to operate on multiple terms, they need to be on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76da107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0e1be",
   "metadata": {},
   "source": [
    "#### 6.7.2.1. Storage on the GPU\n",
    "Ways to store a tensor on the GPU: \n",
    "- specify the storage device when creating a tensor.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e8220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
